{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setup environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nog testen:\n",
    "\n",
    "is het mogelijk om gewoon empty environment te maken, gebasseerd op de imports de juiste libraries te downloaden om vervolgens:\n",
    "\n",
    "conda env export > environment.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "voor empty environment:\n",
    "\n",
    "conda create --name myenv python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for reference:\n",
    "\n",
    "https://github.com/gunthercox/chatterbot-corpus@master#egg=chatterbot_corpus\n",
    "\n",
    "https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz#egg=en_core_web_sm\n",
    "\n",
    "https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.1.0/de_core_news_sm-2.1.0.tar.gz#egg=de_core_news_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requierments.yml file\n",
    "# https://anaconda.org/conda-forge/chatterbot_corpus\n",
    "\n",
    "name: -\n",
    "channels:\n",
    "  - defaults\n",
    "  - https://conda.anaconda.org/conda-forge/\n",
    "dependencies:\n",
    "  - jupyter=1.0.0\n",
    "  - jupyterlab=4.0.11\n",
    "  - scikit-learn\n",
    "  - matplotlib\n",
    "  - numpy\n",
    "  - pandas\n",
    "  - ChatterBot==1.0.5\n",
    "  - chatterbot-corpus==1.2.0\n",
    "  - click==8.1.7\n",
    "  - coveralls\n",
    "  - flake8\n",
    "  - joblib==1.4.2\n",
    "  - mathparse>=0.1,<0.2\n",
    "  - nltk>=3.2,<4.0\n",
    "  - nose\n",
    "  - pint>=0.8.1\n",
    "  - pymongo>=3.3,<4.0\n",
    "  - python-dateutil>=2.8,<2.9\n",
    "  - pytz\n",
    "  - pyyaml>=5.3,<5.4\n",
    "  - regex==2024.7.24\n",
    "  - six==1.16.0\n",
    "  - twine\n",
    "  - twython\n",
    "  - spacy>=2.1,<2.2\n",
    "  - sphinx>=3.0,<3.1\n",
    "  - sphinx_rtd_theme\n",
    "  - sqlalchemy>=1.3,<1.4\n",
    "  - tqdm==4.66.5\n",
    "  - python == 3.7.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conda commands:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conda env create --file requirements.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eenmalig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "indien er nog een librarie mist, dan kan je dit doen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install <librarie>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleaner import clean_corpus\n",
    "\n",
    "from chatterbot import ChatBot\n",
    "from chatterbot.trainers import ListTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inzichten in de corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS_FILE = \"chat.txt\"\n",
    "cleaned_corpus = clean_corpus(CORPUS_FILE)\n",
    "\n",
    "with open(\"clean_corpus_file.txt\", mode=\"w\", encoding=\"utf-8\") as clean_corpus_file:\n",
    "    clean_corpus_file.write(str(cleaned_corpus))\n",
    "    # clean_corpus_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"corpus_file.txt\", mode=\"w\", encoding=\"utf-8\") as teks_file:\n",
    "        with open(\"chat.txt\", \"r\", encoding=\"utf-8\") as corpus_file:\n",
    "            content = corpus_file.read()\n",
    "            teks_file.write(content)\n",
    "\n",
    "\n",
    "# dit alles hoeft dus niet, je kan dan gewoon de chat.txt file gebruiken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: a.d.h.v. format van clean_corpus_file.txt trainen, atm 1 lange slang\n",
    "# maar je kan deze in losse branches maken:\n",
    "''' \n",
    "trainer = ListTrainer(chatbot)\n",
    "\n",
    "trainer.train([\n",
    "    \"Hi there!\",\n",
    "    \"Hello\",\n",
    "])\n",
    "\n",
    "trainer.train([\n",
    "    \"Greetings!\",\n",
    "    \"Hello\",\n",
    "])\n",
    "\n",
    "trainer.train([\n",
    "    \"How are you?\",\n",
    "    \"I am good.\",\n",
    "    \"That is good to hear.\",\n",
    "    \"Thank you\",\n",
    "    \"You are welcome.\",\n",
    "])\n",
    "\n",
    "'''\n",
    "\n",
    "# todo:\n",
    "# hoe een ml model maken met bovenstaande outputs.\n",
    "\n",
    "# data verzamelen vanaf:\n",
    "#  - client/employee chat\n",
    "#  - q&a forum\n",
    "#  - faq\n",
    "#  - ervaring vd sales/consultants\n",
    "#  - ...\n",
    "# wat zijn keywords in deze data?\n",
    "# deze data kan ook zonder machine learning gebruikt worden, zie dit als baseline\n",
    "\n",
    "# ml:\n",
    "#  - frequent pattern mining, welke reactie is het meest voorkomend? (deze pattern toevoegen aan trainer.train)\n",
    "#  - nlp, wat bedoeld de gebruiker? -> suggesties maken in trainer.train (\"bedoeld u x, y of z?\")\n",
    "#  - reinforcement learning -> gebruiker kan responces liken/disliken"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
